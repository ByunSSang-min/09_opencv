## ğŸŸ© Personal project using cascade classifier

### ğŸ“· #1 Python Code (haar_utils.py, 6_project01.py)

![Required](result_screenshot/6_0.jpg)

1. First, prepare the cascade classifier files in data folder.

   ë¨¼ì €, ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° íŒŒì¼ì„ ë°ì´í„° í´ë”ì— ë„£ìŠµë‹ˆë‹¤.

<br>

2. haar_utils.py -> A code for importing contains various utilities like distinguishing genders  
   6_project01.py -> Main code that should be executed

   haar_utils.py -> ì„±ë³„ êµ¬ë¶„ ë“±ì˜ ì—¬ëŸ¬ ê¸°ëŠ¥ì´ í¬í•¨ëœ ì„í¬íŒ…ìš© ì½”ë“œ  
   6_project01.py -> ì‹¤í–‰ì‹œì¼œì•¼ í•˜ëŠ” ë©”ì¸ ì½”ë“œ

```python
# haar_utils.py
# ì—¬ëŸ¬ ê¸°ëŠ¥ë“¤ì´ ë‹´ê¸´ ì½”ë“œ
# ì‹¤í–‰ì‹œí‚¬ ì½”ë“œì—ì„œ import í•œ í›„ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°í•˜ë©´ ë¨

import cv2
import numpy as np

def preprocessing(fname):
    img = cv2.imread('../img/'+fname, cv2.IMREAD_COLOR)
    
    if img is None :
        return None, None
    
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    img_gray = cv2.equalizeHist(img_gray)
    
    return img, img_gray

def correct_image(img, face_center, eye_centers):
    pt0, pt1 = eye_centers
    
    if pt0[0] > pt1[0]:
        pt0, pt1 = pt1, pt0
    dx, dy = np.subtract(pt1, pt0)
    
    angle = cv2.fastAtan2(float(dy), float(dx))
    
    rot_matrix = cv2.getRotationMatrix2D((float(face_center[0]), float(face_center[1])), angle, 1)
    size = img.shape[1::-1]
    img_correction = cv2.warpAffine(img, rot_matrix, size, cv2.INTER_CUBIC)
    
    eye_centers = np.expand_dims(eye_centers, axis=0)
    eye_correct_centers = cv2.transform(eye_centers, rot_matrix)
    eye_correct_centers = np.squeeze(eye_correct_centers, axis=0)
    
    return img_correction, eye_correct_centers


def define_roi(pt, size):
    return np.ravel((pt, size)).astype('int')

def detect_object(center, face):
    w, h = np.array(face[2:4])
    center = np.array(center)
    
    gap_face = np.multiply((w, h), (0.45, 0.65))
    pt_face_start = center - gap_face
    pt_face_end = center + gap_face
    hair = define_roi(pt_face_start, pt_face_end - pt_face_start)
    
    size = np.multiply(hair[2:4], (1, 0.4))
    hair_upper = define_roi(pt_face_start, size)
    hair_lower = define_roi(pt_face_end - size, size)
    
    gap_lip = np.multiply((w, h), (0.18, 0.10))
    lip_center = center +(0, int(h*0.3))
    
    pt_lip_start = lip_center - gap_lip
    pt_lip_end = lip_center + gap_lip
    
    lip = define_roi(pt_lip_start, pt_lip_end - pt_lip_start)
    
    return [hair_upper, hair_lower, lip, hair]

def draw_ellipse(img, roi, ratio, color, thickness=cv2.FILLED):
    x, y, w, h = roi
    center = (x+w//2, y+h//2)
    size = (int(w*ratio), int(h*ratio))
    cv2.ellipse(img, center, size, 0, 0, 360, color, thickness)
    return img

def make_masks(rois, shape):
    base_mask = np.full(shape, 255, np.uint8)
    
    hair_mask = draw_ellipse(base_mask, rois[3], 0.45, 0)
    cv2.imshow('hair_maks', hair_mask)
    
    lip_mask = draw_ellipse(np.copy(hair_mask), rois[2], 0.40, 255)
    cv2.imshow('lip_mask', lip_mask)
    
    masks = [hair_mask, hair_mask, lip_mask, ~lip_mask]
    masks = [mask[y:y+h, x:x+w] for mask, (x, y, w, h) in zip(masks, rois)]
    
    return masks

def calc_histo(img, rois, masks):
    bsize = (64, 64, 64)
    ranges = (0, 256, 0, 256, 0, 256)
    sub_imgs = [img[y:y+h, x:x+w] for x, y, w, h in rois]
    
    hists = [cv2.calcHist([sub_img], [0, 1, 2], mask, bsize, ranges, 3)
             for sub_img, mask in zip(sub_imgs, masks)]
    hists = [h/np.sum(h) for h in hists]
    
    sim_face_lip = cv2.compareHist(hists[2], hists[3], cv2.HISTCMP_CORREL)
    sim_hair = cv2.compareHist(hists[0], hists[1], cv2.HISTCMP_CORREL)
    return sim_face_lip, sim_hair

def classify_gender(img, sims):
    criteria = 0.25 if sims[0] > 0.2 else 0.1
    gender = 'Woman' if sims[1] > criteria else 'Man'
    
    print(gender+' : ì…ìˆ -ì–¼êµ´ ìœ ì‚¬ë„ %4.2f, ìœ—-ê·€ë°‘ë¨¸ë¦¬ ìœ ì‚¬ë„ %4.2f' %(sims))
    return gender

def display(img, face_center, eye_centers, rois, gender):
    cv2.circle(img, face_center, 2, (0, 0, 255), 2)
    
    cv2.circle(img, tuple(eye_centers[0]), 20, (0, 255, 0), 2)
    cv2.circle(img, tuple(eye_centers[1]), 20, (0, 255, 0), 2)
    
    draw_ellipse(img, rois[2], 0.45, (0, 0, 255), 2)
    draw_ellipse(img, rois[3], 0.45, (0, 0, 255), 2)
    
    cv2.putText(img, gender, (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 0, 0), 3)
    cv2.imshow('final result', img)

```

---

```python
# 6_project01.py
# ì„±ë³„ ë¶„ë¥˜ ì™„ë£Œ
# ì „ì²˜ë¦¬ í•¨ìˆ˜ ë° ë³´ì • ì´ë¯¸ì§€ í•¨ìˆ˜ í¬í•¨

from haar_utils import *

# cascade classifier ë¡œë“œ
face_cascade = cv2.CascadeClassifier('../data/haarcascade_frontalface_alt2.xml')
eye_cascade = cv2.CascadeClassifier('../data/haarcascade_eye.xml')


img, img_gray = preprocessing('sullyoon.jpg')


# ì´ë¯¸ì§€ ë¡œë“œì— ì‹¤íŒ¨í•  ê²½ìš° ì˜ˆì™¸(Exception) ë°œìƒì‹œí‚´
if img is None:
    raise Exception('ì‚¬ì§„ì„ ì—¬ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')

faces = face_cascade.detectMultiScale(img_gray)
print('ì°¾ì€ ì–¼êµ´ ìˆ˜ : %d' % len(faces))

#ëª¨ë“  ì–¼êµ´ì„ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
for (x, y, w, h) in faces:
    # ì–¼êµ´ì˜ ì´ë¯¸ì§€ ì˜ì—­ ìë¥´ê¸°
    face_gray = img_gray[y:y+h, x:x+w]
    face_img = img[y:y+h, x:x+w]

    # ëˆˆ ì¸ì‹í•˜ê¸°
    eyes = eye_cascade.detectMultiScale(face_gray, 1.1, 2, 0, (30,30), (80,80))
    print('ì°¾ì€ ëˆˆì˜ ìˆ˜ : %d' % len(eyes))

    if len(eyes) == 2:  # ì°¾ì€ ëˆˆì˜ ìˆ˜ê°€ 2ê°œì¼ ê²½ìš°
        face_center = (x+w//2, y+h//2)  # ì–¼êµ´ì˜ ì¤‘ì‹¬ì , // --> ëª«ì„ ì·¨í•¨
        # ëˆˆì˜ ì¤‘ì‹¬ì ë“¤ --> í˜„ì¬ ëˆˆì€ 2ê°œ ì°¾ìŒ
        eye_centers = [(x+ex+ew//2, y+ey+eh//2) for ex,ey,ew,eh in eyes]
        # ë³´ì •ëœ ì´ë¯¸ì§€ì™€ ë³´ì •ëœ ëˆˆì˜ ì¤‘ì‹¬ì  êµ¬í•¨
        corr_img, corr_eye_centers = correct_image(img, face_center, eye_centers)

        # ë¨¸ë¦¬ì¹´ë½/ì…ìˆ  ì˜ì—­ ì¶”ì¶œ --> faces[0]ì€ ì²«ë²ˆì§¸ ì–¼êµ´
        # rois --> [hair upper, hair lower, lip, hair]
        rois = detect_object(face_center, faces[0])
        # ë„¤ê°œì˜ ë§ˆìŠ¤í¬ êµ¬í•˜ê¸°, ì…ë ¥ì€ ë„¤ê°œì˜ ì˜ì—­ê³¼ ìˆ˜ì •ëœ ì´ë¯¸ì§€ì˜ í¬ê¸°
        # 4ê°œì˜ ì˜ì—­ --> ìœ—ë¨¸ë¦¬, ê·€ë¨¸ë¦¬ì¹´ë½, ì…ìˆ , ì–¼êµ´(ë¨¸ë¦¬ì¹´ë½)
        masks = make_masks(rois, corr_img.shape[:2])

        # ìœ ì‚¬ë„ ê³„ì‚° ë° ì¶œë ¥
        sims = calc_histo(corr_img, rois, masks)
        # ë‚¨ë…€ ì„±ë³„ êµ¬ë¶„ --> ì´ë¯¸ì§€ ë° ì¶œë ¥ë¬¸ìœ¼ë¡œ ì„±ë³„ í‘œì‹œ
        gender = classify_gender(img, sims)
        # ì¶œë ¥ --> ì–¼êµ´, ëˆˆ, ì…ìˆ  ì£¼ìœ„ì— ë„í˜• í‘œì‹œ
        display(corr_img, face_center, corr_eye_centers, rois, gender)

cv2.waitKey(0)
cv2.destroyAllWindows()

```

---

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/6_1.jpg)

<br>

![Result](result_screenshot/6_2.jpg)

3. According to masking of hair and lip, it determines the gender of person in image.

   ë¨¸ë¦¬ì¹´ë½ ë¶€ë¶„ê³¼ ì…ìˆ  ë¶€ë¶„ì˜ ë§ˆìŠ¤í‚¹ì— ë”°ë¼ ì‚¬ì§„ ì† ì¸ë¬¼ì˜ ì„±ë³„ì„ ê²°ì •í•©ë‹ˆë‹¤.

<br>