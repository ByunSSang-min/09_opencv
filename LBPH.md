## ğŸŸ¦ LBPH

### ğŸ“· #1 Python Code (3_lbp_face1_collect.py)

1. This project records up to photos when a face is detected by the camera.

ì¹´ë©”ë¼ì— ì–¼êµ´ì´ ì¡íˆë©´ ìë™ìœ¼ë¡œ ì‚¬ì§„ì„ ì°ì–´ì„œ ê¸°ë¡í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

```python
import cv2
import numpy as np
import os 

# ë³€ìˆ˜ ì„¤ì • ---â‘ 
base_dir = '../result_screenshot/faces/'   # ì‚¬ì§„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
target_cnt = 401        # ìˆ˜ì§‘í•  ì‚¬ì§„ ê°¯ìˆ˜
cnt = 1                 # ì‚¬ì§„ ì´¬ì˜ ìˆ˜

# ì–¼êµ´ ê²€ì¶œ ë¶„ë¥˜ê¸° ìƒì„± --- â‘¡
face_classifier = cv2.CascadeClassifier(\
                    '../data/haarcascade_frontalface_default.xml')

# ì‚¬ìš©ì ì´ë¦„ê³¼ ë²ˆí˜¸ë¥¼ ì…ë ¥ ë°›ì•„ ë””ë ‰í† ë¦¬ ìƒì„± ---â‘¢
name = input("ìœ ì € ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì•ŒíŒŒë²³ë§Œ ì…ë ¥!): ")
id = input("ìœ ì € ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¤‘ë³µ ê¸ˆì§€!): ")
dir = os.path.join(base_dir, name+'_'+ id)
if not os.path.exists(dir):
    os.mkdir(dir)

# ì¹´ë©”ë¼ ìº¡ì³ 
cap = cv2.VideoCapture(1)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while cap.isOpened():
    ret, frame = cap.read()
    if ret:
        img = frame.copy()
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        # ì–¼êµ´ ê²€ì¶œ --- â‘£
        faces = face_classifier.detectMultiScale(gray, 1.3, 5)
        if len(faces) == 1:
            (x,y,w,h) = faces[0]
            # ì–¼êµ´ ì˜ì—­ í‘œì‹œ ë° íŒŒì¼ ì €ì¥ ---â‘¤
            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 1)
            face = gray[y:y+h, x:x+w]
            face = cv2.resize(face, (200, 200))
            file_name_path = os.path.join(dir,  str(cnt) + '.jpg')
            cv2.imwrite(file_name_path, face)
            cv2.putText(frame, str(cnt), (x, y), cv2.FONT_HERSHEY_COMPLEX, \
                             1, (0,255,0), 2)
            cnt+=1
        else:
            # ì–¼êµ´ ê²€ì¶œì´ ì—†ê±°ë‚˜ 1ì´ìƒ ì¸ ê²½ìš° ì˜¤ë¥˜ í‘œì‹œ ---â‘¥
            if len(faces) == 0 :
                msg = "no face."
            elif len(faces) > 1:
                msg = "too many face."
            cv2.putText(frame, msg, (10, 50), cv2.FONT_HERSHEY_DUPLEX, \
                            1, (0,0,255))
        cv2.imshow('face record', frame)
        if cv2.waitKey(1) == 27 or cnt == target_cnt: 
            break
cap.release()
cv2.destroyAllWindows()      
print("ì–¼êµ´ ìƒ˜í”Œ ìˆ˜ì§‘ì´ ëë‚¬ìŠµë‹ˆë‹¤.")

```

---

<br>

![Required](result_screenshot/3.jpg)

2. When the code is executed, input your name(only alphabet) and ID(only number) that you want.

ì½”ë“œê°€ ì‹¤í–‰ë˜ë©´, ë‹¹ì‹ ì´ ì›í•˜ëŠ” ì´ë¦„(ì•ŒíŒŒë²³ë§Œ ì…ë ¥)ì´ë‘ ID(ìˆ«ìë§Œ ì…ë ¥)ì„ ì…ë ¥í•©ë‹ˆë‹¤.

<br><br>

![Required](result_screenshot/3_1.jpg)

3. After setting name and ID, the camera will take photos of yours whenever it recognizes your face.

ì´ë¦„ê³¼ IDë¥¼ ì •í–ˆìœ¼ë©´, ì¹´ë©”ë¼ì— ë‹¹ì‹ ì˜ ì–¼êµ´ì´ ì¸ì‹ë  ë•Œë§ˆë‹¤ ì‚¬ì§„ì´ ì°í ê²ƒì…ë‹ˆë‹¤.

<br><br>

![Result](result_screenshot/3_2.jpg)

4. It will records up to maximum 400 photos.

ìµœëŒ€ 400ì¥ì˜ ì‚¬ì§„ê¹Œì§€ ê¸°ë¡ë©ë‹ˆë‹¤.

<br><br>

![Result](result_screenshot/3_3.jpg)

5. The photos that were recorded are saved in result_screenshot/faces/(name)_(id) directory.

ê¸°ë¡ëœ ì‚¬ì§„ë“¤ì€ result_screenshot/faces/(name)_(id) í´ë” ê²½ë¡œì— ì €ì¥ë©ë‹ˆë‹¤.

---

### ğŸ“· #2 Python Code (4_lbp_face2_train.py)

1. Now, take the photos that were recorded and train them using LBPH algorithm model.

ì´ì œ ê¸°ë¡ëœ ì‚¬ì§„ë“¤ì„ ê°€ì ¸ë‹¤ê°€ LBPH ì•Œê³ ë¦¬ì¦˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ë§ í›ˆë ¨ì„ í•©ì‹œë‹¤.

```python
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì • --- â‘ 
base_dir = '../result_screenshot/faces'
train_data, train_labels = [], []


dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]

print('í›ˆë ¨ ë°ì´í„°ì…‹ ìˆ˜ì§‘: ')
for dir in dirs:
    # name_id í˜•ì‹ì—ì„œ idë¥¼ ë¶„ë¦¬ ---â‘¡
    id = dir.split('_')[2]          
    files = glob.glob(dir+'/*.jpg')
    print('\t path:%s, %dfiles'%(dir, len(files)))
    for file in files:
        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
        # ì´ë¯¸ì§€ëŠ” train_data, ì•„ì´ë””ëŠ” train_lablesì— ì €ì¥ ---â‘¢
        train_data.append(np.asarray(img, dtype=np.uint8))
        train_labels.append(int(id))

# NumPy ë°°ì—´ë¡œ ë³€í™˜ ---â‘£
train_data = np.asarray(train_data)
train_labels = np.int32(train_labels)

# LBP ì–¼êµ´ì¸ì‹ê¸° ìƒì„± ë° í›ˆë ¨ ---â‘¤
print('LBP ëª¨ë¸ í›ˆë ¨ ì‹œì‘...')
model = cv2.face.LBPHFaceRecognizer_create()
model.train(train_data, train_labels)
model.write('../result_screenshot/faces/Byun_face.xml')
print("ëª¨ë¸ í›ˆë ¨ ì„±ê³µ!")

```

---

<br>

![Required](result_screenshot/4_1.jpg)

2. When the code is executed, the modeling training will be started with collected dataset.

ì½”ë“œê°€ ì‹¤í–‰ë˜ë©´, ìˆ˜ì§‘ëœ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  ëª¨ë¸ë§ í›ˆë ¨ì´ ì‹œì‘ë  ê²ƒì…ë‹ˆë‹¤.

<br><br>

![Required](result_screenshot/4_2.jpg)

3. Once the training is complete, the result will be saved in the faces folder.

í›ˆë ¨ì´ ëë‚˜ë©´, faces í´ë”ì— ê²°ê³¼ê°€ ì €ì¥ë  ê²ƒì…ë‹ˆë‹¤.

---

### ğŸ“· #3 Python Code (5_lbp_face2_train.py)

1. Finally, let's check the camera whether it recognizes our face or not.

ìµœì¢…ì ìœ¼ë¡œ, ì¹´ë©”ë¼ê°€ ìš°ë¦¬ ì–¼êµ´ì„ ì¸ì‹í•˜ëŠ”ì§€ ëª»í•˜ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.

```python
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì • ---â‘ 
base_dir = '../result_screenshot/faces'
min_accuracy = 85

# LBP ì–¼êµ´ ì¸ì‹ê¸° ë° ì¼€ìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œê¸° ìƒì„± ë° í›ˆë ¨ ëª¨ë¸ ì½ê¸° ---â‘¡
face_classifier = cv2.CascadeClassifier('../data/haarcascade_frontalface_default.xml')
model = cv2.face.LBPHFaceRecognizer_create()
model.read(os.path.join(base_dir, 'Byun_face.xml'))

# ë””ë ‰í† ë¦¬ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ì ì´ë¦„ê³¼ ì•„ì´ë”” ë§¤í•‘ ì •ë³´ ìƒì„± ---â‘¢
dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]
names = dict([])
for dir in dirs:
    dir = os.path.basename(dir)
    name, id = dir.split('_')
    names[int(id)] = name

# ì¹´ë©”ë¼ ìº¡ì²˜ ì¥ì¹˜ ì¤€ë¹„ 
cap = cv2.VideoCapture(1)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("í”„ë ˆì„ ì—†ìŒ")
        break
    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    # ì–¼êµ´ ê²€ì¶œ ---â‘£
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
        # ì–¼êµ´ ì˜ì—­ í‘œì‹œí•˜ê³  ìƒ˜í”Œê³¼ ê°™ì€ í¬ê¸°ë¡œ ì¶•ì†Œ ---â‘¤
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)
        face = frame[y:y+h, x:x+w]
        face = cv2.resize(face, (200, 200))
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        # LBP ì–¼êµ´ ì¸ì‹ê¸°ë¡œ ì˜ˆì¸¡ ---â‘¥
        label, confidence = model.predict(face)
        if confidence < 400:
            # ì •í™•ë„ ê±°ë¦¬ë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜ ---â‘¦
            accuracy = int( 100 * (1 -confidence/400))
            if accuracy >= min_accuracy:
                msg =  '%s(%.0f%%)'%(names[label], accuracy)
            else:
                msg = 'Unknown'
        # ì‚¬ìš©ì ì´ë¦„ê³¼ ì •í™•ë„ ê²°ê³¼ ì¶œë ¥ ---â‘§
        txt, base = cv2.getTextSize(msg, cv2.FONT_HERSHEY_PLAIN, 1, 3)
        cv2.rectangle(frame, (x,y-base-txt[1]), (x+txt[0], y+txt[1]), \
                    (0,255,255), -1)
        cv2.putText(frame, msg, (x, y), cv2.FONT_HERSHEY_PLAIN, 1, \
                    (200,200,200), 2,cv2.LINE_AA)
    cv2.imshow('Face Recognition', frame)

    # ESC ëˆ„ë¥´ë©´ ì¢…ë£Œ
    if cv2.waitKey(1) == 27:
        break
cap.release()
cv2.destroyAllWindows()

```

---

<br>

![Required](result_screenshot/5.jpg)

2. If there was no issue with modeling training or dataset, the camera will able to recognize  
your face without any problem.

ëª¨ë¸ë§ í›ˆë ¨ì´ë‚˜ ë°ì´í„°ì…‹ì— ë¬¸ì œê°€ ì—†ì—ˆë‹¤ë©´, ì¹´ë©”ë¼ê°€ ë‹¹ì‹ ì˜ ì–¼êµ´ì„ ë¬¸ì œì—†ì´ ì¸ì‹í•  ê²ƒì…ë‹ˆë‹¤.

---